{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica de aprendizaje semi supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta práctica vamos a implementar el algoritmo `self-training` para abordar un problema de aprendizaje semi-supervisado con la metodología inductive learning. \n",
    "\n",
    "En concreto, para desarrollar la práctica vamos a trabajar con el dataset Ionosphere. Este dataset contiene la información de un problema en el que un sistema de radar recoge información de 16 antenas con el objetivo de ver si los electrones presentan algún tipo de estructura en la ionosfera (Bueno) o no (Malo). Toda la información de este dataset se puede encontrar en la URL: https://archive.ics.uci.edu/ml/datasets/Ionosphere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para leer los datos del dataset se facilita la clase dataset (`dataset.py`). Dicha clase tiene un método llamado `lecturaDatos` con los siguientes parámetros de entrada y de salida:\n",
    "\n",
    "* Entrada: nombre del archivo que contiene los datos del problema a resolver\n",
    "* Salida: un objeto dataset que sigue la estructura de los datasets nativos de scikit-learn.\n",
    "\n",
    "El objeto dataset tiene los siguientes campos con diferente información:\n",
    "* data: contiene los datos leídos del fichero.\n",
    "* target: contiene las clases del problema.\n",
    "* feature_names: es una lista con los nombres de las variables de entrada del problema.\n",
    "* target_names: es una lista con los nombres de las clases del problema.\n",
    "\n",
    "Para utilizarla, en primer lugar hay que importar el paquete dataset (además importaremos todos las clases necesarias para el desarrollo de la práctica)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, model_selection, metrics\n",
    "import dataset as ds\n",
    "from test_helper import Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realiza la lectura de los datos almacenados en el fichero `ionosphere.dat` y guardar el resultado en una variable llamada ion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lectura de los datos del problema y guardado del resultado en la variable llamada ion\n",
    "ion = ds.lecturaDatos(\"ionosphere.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 1: Una vez leído el dataset vamos a simular un problema de aprendizaje semi-supervisado. En primer lugar vamos a dividir el dataset en dos conjuntos (entrenamiento y test) mediante el método de validación hold-out. Utilizar para ello la función train_test_split de la librería model_selection, cuya información la podéis encontrar en la URL: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split\n",
    "\n",
    "Utilizar el 30% de los datos para test y el valor 2 como semilla para realizar el particionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realizamos el particionamiento hold-out\n",
    "X_train_ini, X_test_ini, y_train_ini, y_test_ini = model_selection.train_test_split(ion.data, ion.target, test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta práctica vamos a utilizar como clasificador una máquina de soporte vectorial (SVM). La librería que contiene las máquinas de soporte vectorial se llama `svm` (la hemos importado al principio de la práctica) y la clase correspondiente al clasificador que vamos a utilizar se llama `SVC`. Toda la información de dicha clase se encuentra en la URL: http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "Vamos a obtener su porcentaje de acierto en circunstancias normales (aprendizaje supervisado).\n",
    "\n",
    "Paso 2: Crear una SVM (utilizar los valores por defecto en la llamada al constructor salvo el parámetro `probability` que debéis asignarlo a `True`y el `random_state` que debe tomar el valor 1), aprender el clasificador utilizando los datos de entrenamiento y predecir las clases de los datos de test. Calcular y mostrar el porcentaje de acierto sobre 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con hold-out original 100%, resultado en test: 85.8490566038\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# Llamamos al constructor de SVC (parámetro probability a True y la semilla a 1)\n",
    "cl = svm.SVC(probability=True,random_state=1)\n",
    "# Entrenamiento del clasificador con los ejemplos de entrenamiento\n",
    "cl = cl.fit(X_train_ini, y_train_ini)\n",
    "# Prediccion de las clases de los ejemplos de test\n",
    "pr = cl.predict(X_test_ini)\n",
    "# Obtenemos e imprimimos el porcentaje de acierto\n",
    "accuracyAS = metrics.accuracy_score(y_test_ini, pr)*100\n",
    "print (\"Con hold-out original 100%, resultado en test: \" + str(accuracyAS))\n",
    "\n",
    "Test.assertEquals(round(accuracyAS, 2), 85.85, 'Accuracy en aprendizaje supervisado incorrecto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 3: Una vez obtenidos ambos conjuntos de ejemplos vamos a simular el problema de aprendizaje semi-supervisado.  Para ello vamos a volver a aplicar la función que nos particiona un conjunto de datos en entrenamiento y test (`train_test_split`) pero esta vez en lugar de pasar como argumento de entrada todo el dataset solamente utilizaremos los datos de entrenamiento obtenidos en la etapa anterior. En esta ocasión los datos de la salida de la función train_test_split (X_train, X_test, y_train, y_test) correspondientes a los datos de entrenamiento serán el conjunto L y las clases de dicho conjunto. Los datos de test serán el conjunto U y sus clases asociadas serán ignoradas. Utilizar un 70% de los datos para test (corresponde a la situación de tener un 30% de los datos disponibles, en L, para entrenar). Utilizar 2 como valor de semilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realizamos el particionamiento hold-out usando como entrada los ejemplos de entrenamiento obtenidos anteriormente\n",
    "L, U, L_target, a = model_selection.train_test_split(X_train_ini, y_train_ini, test_size=0.7, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 4: entrenar la SVM con los datos y las clases asociadas a L y predecir las clases de los datos de test (los obtenidos en el paso 1). Calcular el porcentaje de acierto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con 30.0% de train sin SSL, resultado en test: 77.358490566\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# Llamamos al constructor de SVC (parámetro probability a True y la semilla a 1)\n",
    "cl = svm.SVC(probability=True,random_state=1)\n",
    "# Entrenamiento del clasificador con los ejemplos del subconjunto L\n",
    "cl = cl.fit(L, L_target)\n",
    "# Prediccion de las clases de los ejemplos de test iniciales\n",
    "pr = cl.predict(X_test_ini)\n",
    "# Obtenemos e imprimimos el porcentaje de acierto sin aplicar aprendizaje semi-supervisado\n",
    "accuracySinSSL = metrics.accuracy_score(y_test_ini, pr)*100\n",
    "print \"Con \" + str((1-0.7)*100) + \"% de train sin SSL, resultado en test: \" + str(accuracySinSSL)\n",
    "\n",
    "Test.assertEquals(round(accuracySinSSL, 2), 77.36, 'Accuracy en aprendizaje supervisado incorrecto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 5: aplicar el algoritmo self-training para etiquetar y aprender un clasificador con los datos de L y con los datos de U siguiendo estas 11 etapas\n",
    "1.\tEntrenar la SVM con los ejemplos y las clases de L\n",
    "2.\tPredecir las probabilidades de las clases de los datos en U (no se debe usar `predict` directamente sino que se debe usar el método `predict_proba`). Este método devuelve para cada ejemplo la probabilidad de cada clase (la clase con más probabilidad sería la predicha). Por tanto, devuelve una lista de listas (tantas filas como ejemplos y tantas columnas como clases).\n",
    "3.\tOrdenar dichas probabilidades por cada ejemplo (por filas, eje 1). Utilizar `np.sort` y ordenando de menor a mayor (por defecto). Guardar el resultado en una variable auxiliar.\n",
    "4.\tOrdenar de nuevo las probabilidades de cada ejemplo pero esta vez para coger los índices (`np.argsort`). Guardar el resultado en otra variable auxiliar. La clase predicha estará en la última columna ya que la mayor predicción obtenida en el paso anterior también estará en dicha columna.\n",
    "5.\tOrdenar las probabilidades de la última columna obtenidas en el paso 3 (las de las predicciones) para coger los índices.\n",
    "6.\tSeleccionar los ejemplos de U correspondientes a los k últimos índices obtenidos en el paso 5.Serán los ejemplos con mayores confianzas en su predicción. K es el número de ejemplos a añadir en cada iteración del algoritmo.\n",
    "7.\tEliminar los ejemplos anteriores de U. Utilizar la función `np.delete(matriz, indicesEliminar, 0)`, el 0 es por eliminar por filas (eje 0).\n",
    "8.\tSeleccionar las clases predichas para estos ejemplos. Serán las guardadas en las últimas k posiciones del resultado de la etapa 4.\n",
    "9.\tAñadir los ejemplos obtenidos en la etapa 6 a L. Utilizar la función `np.vstack((L, ejemplosAñadir))`.\n",
    "10.\tAñadir las clases predichas para dichos ejemplos a las clases asociadas a L. Utilizar la función `np.hstack((clasesL,clasesPredichasEjemplosAñadidos))`.\n",
    "11.\tRepetir este proceso hasta que no haya más ejemplos en U.\n",
    "\n",
    "Utilizar 1 como valor de k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# Llamamos al constructor de SVC (parámetro probability a True y la semilla a 1)\n",
    "cl = svm.SVC(probability=True,random_state=1)\n",
    "# Asignamos el valor de k (número de ejemplos a etiquetar en cada iteración)\n",
    "k = 1\n",
    "# Mientras haya ejemplos en U\n",
    "while U.shape[0]>0:\n",
    "    # Entrenamiento del clasificador con los ejemplos del subconjunto L    \n",
    "    cl = cl.fit(L, L_target)\n",
    "    # Prediccion de las probabilidades de los ejemplos del subconjunto U (no etiquetados)\n",
    "    pr = cl.predict_proba(U)\n",
    "    # Ordenar las probabilidades por filas\n",
    "    prAux = np.sort(pr,axis=1)\n",
    "    # Obtener los índices (clases) al ordenar las probabilidades por filas\n",
    "    clasesAux = np.argsort(pr,axis=1)\n",
    "    # Obtener los índices al ordenar la última columna de las probabilidades ordenadas anteriormente\n",
    "    indices = np.argsort(prAux[:,-1])\n",
    "    # Seleccionar los k últimos ejemplos de U\n",
    "    ejemplos = U[indices[-k:]]\n",
    "    # Seleccionar los k últimas clases predichas para los ejemplos de U\n",
    "    clases = np.argmax(clasesAux[indices[-k:]], axis=1)\n",
    "    # Añadir al subconjunto L los ejemplos etiquetados en la iteración\n",
    "    L = np.vstack((L,ejemplos))\n",
    "    # Añadir las clases de los ejemplos etiquetados en la iteración (al subconjunto L_target)\n",
    "    L_target = np.hstack((L_target,clases))\n",
    "    # Eliminar de U los ejemplos etiquetados en la iteración\n",
    "    U =  np.delete(U, indices[-k:], 0)\n",
    "\n",
    "Test.assertEquals(map(lambda x: int(x), L_target[:10]), [1, 0, 0, 0, 0, 0, 0, 1, 0, 0], 'Clases etiquetadas incorrectamente')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 6: Una vez obtenido el conjunto agrandado en el paso 5 (utilizando k=1), entrenar la SVM con él y predecir las clases de los ejemplos de test (los obtenidos en el paso 1). Calcular el porcentaje de acierto. ¿Mejora con respecto al porcentaje de acierto obtenido en el paso 4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con 30.0% de train con SSL, resultado en test: 80.1886792453\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# Llamamos al constructor de SVC (parámetro probability a True y la semilla a 1)\n",
    "cl = svm.SVC(probability=True,random_state=1)\n",
    "# Entrenamiento del clasificador con los ejemplos del subconjunto L\n",
    "cl = cl.fit(L, L_target)\n",
    "# Prediccion de las clases de los ejemplos de test iniciales\n",
    "predicciones3 = cl.predict(X_test_ini)\n",
    "# Obtenemos e imprimimos el porcentaje de acierto tras aplicar aprendizaje semi-supervisado\n",
    "accuracyConSSL = metrics.accuracy_score(y_test_ini, predicciones3)*100\n",
    "print \"Con \" + str((1-0.7)*100) + \"% de train con SSL, resultado en test: \" + str(accuracyConSSL)\n",
    "\n",
    "Test.assertEquals(round(accuracyConSSL, 2), 80.19, 'Valores de accuracy incorrectos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso 7: Realizar un bucle para determinar el porcentaje de ejemplos de test utilizados para formar los conjuntos L y U (en el paso 3 lo asignábamos al 70%). En este bucle se deben utilizar todos los valores entre el 5% y el 95% con saltos del 5%. En cada iteración realizar los pasos del 3 al 6. En cada iteración almacenar el resultado obtenido al utilizar aprendizaje semi supervisado y al no utilizarlo. Finalmente mostrar ambos vectores en una gráfica comparativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con 100.0% de train sin SSL, resultado en test: 85.8490566038\n",
      "Con 100.0% de train con SSL, resultado en test: 85.8490566038\n",
      "Con 95.0% de train sin SSL, resultado en test: 84.9056603774\n",
      "Con 95.0% de train con SSL, resultado en test: 84.9056603774\n",
      "Con 90.0% de train sin SSL, resultado en test: 84.9056603774\n",
      "Con 90.0% de train con SSL, resultado en test: 84.9056603774\n",
      "Con 85.0% de train sin SSL, resultado en test: 84.9056603774\n",
      "Con 85.0% de train con SSL, resultado en test: 83.0188679245\n",
      "Con 80.0% de train sin SSL, resultado en test: 82.0754716981\n",
      "Con 80.0% de train con SSL, resultado en test: 83.0188679245\n",
      "Con 75.0% de train sin SSL, resultado en test: 79.2452830189\n",
      "Con 75.0% de train con SSL, resultado en test: 83.0188679245\n",
      "Con 70.0% de train sin SSL, resultado en test: 81.1320754717\n",
      "Con 70.0% de train con SSL, resultado en test: 83.0188679245\n",
      "Con 65.0% de train sin SSL, resultado en test: 80.1886792453\n",
      "Con 65.0% de train con SSL, resultado en test: 83.0188679245\n",
      "Con 60.0% de train sin SSL, resultado en test: 81.1320754717\n",
      "Con 60.0% de train con SSL, resultado en test: 83.9622641509\n",
      "Con 55.0% de train sin SSL, resultado en test: 80.1886792453\n",
      "Con 55.0% de train con SSL, resultado en test: 83.9622641509\n",
      "Con 50.0% de train sin SSL, resultado en test: 82.0754716981\n",
      "Con 50.0% de train con SSL, resultado en test: 83.9622641509\n",
      "Con 45.0% de train sin SSL, resultado en test: 80.1886792453\n",
      "Con 45.0% de train con SSL, resultado en test: 83.9622641509\n",
      "Con 40.0% de train sin SSL, resultado en test: 79.2452830189\n"
     ]
    }
   ],
   "source": [
    "# Llamamos al constructor de SVC (parámetro probability a True y la semilla a 1)\n",
    "cl = svm.SVC(probability=True,random_state=1)\n",
    "# Asignamos el valor de k (número de ejemplos a etiquetar en cada iteración)\n",
    "k = 1\n",
    "# Listas para almacenar el rendimiento con y sin aplicar aprendizaje supervisado para cada porcentaje de ejemplos\n",
    "sinSSL = list([])\n",
    "conSSL = list([])\n",
    "# Por cada porcentaje de ejemplos a utilizar como test\n",
    "for porcentaje in np.arange(0,0.96,0.05):\n",
    "    # Realizamos el particionamiento hold-out usando como entrada los ejemplos de entrenamiento obtenidos en el paso 1\n",
    "    L, U, L_target, a = model_selection.train_test_split(X_train_ini, y_train_ini, test_size=porcentaje, random_state=2)\n",
    "    # Entrenamiento del clasificador con los ejemplos del subconjunto L \n",
    "    cl = cl.fit(L, L_target)\n",
    "    # Rendimiento SIN aplicar aprendizaje semi-supervisado\n",
    "    # Prediccion de las clases de los ejemplos de test iniciales\n",
    "    pr = cl.predict(X_test_ini)\n",
    "    # Obtenemos e imprimimos el porcentaje de acierto sin aplicar aprendizaje semi-supervisado\n",
    "    accuracySinSSL = metrics.accuracy_score(y_test_ini, pr)*100\n",
    "    print \"Con \" + str((1-porcentaje)*100.0) + \"% de train sin SSL, resultado en test: \" + str(accuracySinSSL)\n",
    "    \n",
    "    # Aplicamos el aprendizaje semi-supervisado\n",
    "    # Mientras haya ejemplos en U\n",
    "    while U.shape[0]>0:\n",
    "        # Entrenamiento del clasificador con los ejemplos del subconjunto L \n",
    "        cl = cl.fit(L, L_target)\n",
    "        # Prediccion de las probabilidades de los ejemplos del subconjunto U (no etiquetados)\n",
    "        pr = cl.predict_proba(U)\n",
    "        # Ordenar las probabilidades por filas\n",
    "        prAux = np.sort(pr,axis=1)\n",
    "        # Obtener los índices (clases) al ordenar las probabilidades por filas\n",
    "        clasesAux =np.argsort(pr,axis=1)\n",
    "        # Obtener los índices al ordenar la última columna de las probabilidades ordenadas anteriormente\n",
    "        indices = np.argsort(prAux[:,-1])\n",
    "        # Seleccionar los k últimos ejemplos de U \n",
    "        ejemplos = U[indices[-k:]]\n",
    "        # Seleccionar los k últimas clases predichas para los ejemplos de U \n",
    "        clases = np.argmax(clasesAux[indices[-k:]], axis=1)\n",
    "        # Añadir al subconjunto L los ejemplos etiquetados en la iteración\n",
    "        L = np.vstack((L,ejemplos))\n",
    "        # Añadir las clases de los ejemplos etiquetados en la iteración (al subconjunto L_target)\n",
    "        L_target = np.hstack((L_target,clases))\n",
    "        # Eliminar de U los ejemplos etiquetados en la iteración\n",
    "        U = np.delete(U, indices[-k:], 0)\n",
    "        \n",
    "    # Entrenamiento del clasificador con los ejemplos del subconjunto L\n",
    "    cl = cl.fit(L, L_target)\n",
    "    # Prediccion de las clases de los ejemplos de test iniciales\n",
    "    pr = cl.predict(X_test_ini)\n",
    "    # Obtenemos e imprimimos el porcentaje de acierto tras aplicar aprendizaje semi-supervisado\n",
    "    accuracyConSSL = metrics.accuracy_score(y_test_ini, pr)*100\n",
    "    print \"Con \" + str((1-porcentaje)*100.0) + \"% de train con SSL, resultado en test: \" + str(accuracyConSSL)\n",
    "    # Añadimos los rendimientos a la lista correspondiente\n",
    "    sinSSL.append(accuracySinSSL)\n",
    "    conSSL.append(accuracyConSSL)\n",
    "\n",
    "# Creamos la figura\n",
    "plt.figure\n",
    "plt.hold(True)\n",
    "plt.xticks(1-np.arange(0,0.96,0.05), size = 'small', color = 'b', rotation = 45)\n",
    "plt.xlabel(\"Porcentaje de train\")\n",
    "plt.ylabel(\"Accuracy obtenido\")\n",
    "plt.title(\"Comparativa entre SSL y no SSL\")\n",
    "plt.plot(1-np.arange(0,0.96,0.05),sinSSL,'r', linewidth = 2, label = 'Sin SSL')\n",
    "plt.plot(1-np.arange(0,0.96,0.05),conSSL,'g', linewidth = 2, label = 'Con SSL')\n",
    "plt.legend(loc = 4)\n",
    "plt.show()\n",
    "\n",
    "Test.assertEquals(map(lambda x: round(x, 2), sinSSL), [85.85, 84.91, 84.91, 84.91, 82.08, 79.25, 81.13, 80.19, 81.13, 80.19, 82.08, 80.19, 79.25, 78.30, 77.36, 71.70, 73.58, 71.70, 66.98, 57.55], 'Valores de accuracy sin SSL incorrectos')\n",
    "Test.assertEquals(map(lambda x: round(x, 2), conSSL), [85.85, 84.91, 84.91, 83.02, 83.02, 83.02, 83.02, 83.02, 83.96, 83.96, 83.96, 83.96, 83.96, 84.91, 80.19, 79.25, 80.19, 71.7, 78.3, 57.55], 'Valores de accuracy con SSL incorrectos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
